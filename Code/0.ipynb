{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Natural Language Processing Basics\n",
    "\n",
    "## Challenge 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background\n",
    "\n",
    "Once upon a time, in the world of movie production and analysis, there was a dataset known as the IMDB dataset. This dataset was created by a group of movie enthusiasts and data scientists who wanted to gather and analyze information about the world's most popular films.\n",
    "The IMDB dataset contained a wealth of information about thousands of movies, including their release dates, genres, directors, actors, and more. It also included user ratings and reviews, allowing the creators of the dataset to gain insights into what people loved and hated about each film.\n",
    "\n",
    "As the dataset grew, so did its potential to provide valuable insights into the world of film. Data scientists and movie enthusiasts alike were able to use the IMDB dataset to answer questions like which films were the most popular, which directors had the best track records, and which actors were the biggest box office draws.\n",
    "\n",
    "One day, a young data analyst named Elena stumbled upon the IMDB dataset and was immediately fascinated by its potential. She spent countless hours pouring over the data, looking for patterns and relationships that could help her better understand the world of film.\n",
    "\n",
    "Soon, her insights were sought after by film studios and movie production companies, who were eager to know what elements of a film were most likely to make it a hit with audiences. With the help of the IMDB dataset, Elena was able to provide them with valuable information that helped them make better decisions about which films to produce and how to market them.\n",
    "\n",
    "And so, the IMDB dataset became an essential tool for anyone looking to understand the world of film. From film students to Hollywood executives, the IMDB dataset continued to provide insights and inspiration to all who used it, helping them to make sense of the complex and ever-changing world of movies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "For this challenge, you will have 2 CSVs: Train and Test. As their names indicate, the first one will be used to train your classification model on the reviews text and test to know to which label they belong (positive or negative).\n",
    "\n",
    "You will have the following attributes to be able to make the classifications:\n",
    "\n",
    "- idx_train or idx_test: Index of the rows\n",
    "- review: Sentence that express the review of a movie\n",
    "- sentiment: Sentiment of the review: Positive or Negative\n",
    "\n",
    "- The test will be based con the label assignation to the test dataset.\n",
    "\n",
    "There are three downloadable files:\n",
    "\n",
    "- train.csv: It is a table that relates the reviews of the training dataset with the attributes described above.\n",
    "- test.csv: It is a table that relates the reviews of the test dataset with the attributes described above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task\n",
    "\n",
    "Create a classification predictive model in order to be able to classify the testing reviews. First train your model with the training images, once you have the model that maximize the f1-score (macro.) use the test images as input for your model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submission\n",
    "\n",
    "### File 1: predictions.json\n",
    "Predictions must be in a JSON file named as predictions.json, an example can be found in the following link\n",
    "\n",
    "In this predictions file, in json format, each row will correspond to the predicted value of the idx_test , i.e. if the first value is a 2 it means that this 2 corresponds to the first file of the test dataset. It is **IMPORTANT** to call the column **target** as specified in the format. Remember that you can use the to_json function of pandas to convert your dataframe to json, length of predictions has to be the same as in test.csv.\n",
    "\n",
    "The objectives score will come from applying the f1-score of the predictions you have made to the testing dataset with our ground truth.\n",
    "\n",
    "**IMPORTANT**: Your predictions must be in int format (0, 1)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "\n",
    "The evaluation will be taken into consideration the following:\n",
    "\n",
    "- **1200/1200:(OBJECTIVES)** This will be obtained from the f1-score(macro) of the predictive model. Comparing the predictions your model has made about versus ground truth."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}